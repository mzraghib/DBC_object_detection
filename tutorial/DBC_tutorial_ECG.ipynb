{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](./images/images.jpeg)](https://www.deepbrainchain.org)\n",
    "\n",
    "# <center>ECG Arrhythmia Classification using Deep Learning</center>\n",
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, you will learn to apply image classification using Convolutional Neural Networks(CNNs), trained on the DBC network. \n",
    "\n",
    "For executing the steps in the tutorial, you will only be required to install DBC on your computing device since all other dependencies including keras and OpenCV will be covered by a pre-configured, GPU-compatible [docker container image](https://www.docker.com/resources/what-container).\n",
    "\n",
    "The instructions assume a Linux environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the World Health Organization (WHO), cardiovascular diseases\n",
    "(CVDs) are the number one cause of death today. Over 17.7 million people died from CVDs which is an about 31% of all deaths, and over 75% of these deaths occur in low and middle income countries. Arrhythmia is a representative type of CVDs that refers to any irregular change from the normal heart rhythms. There are several types of arrhythmia including atrial fibrillation, premature contraction, ventricular fibrillation, and tachycardia. Although single arrhythmia heartbeat may not have a serious impact on life, continuous arrhythmia beats can result in fatal circumstances. For example, prolonged premature ventricular contractions (PVCs) beats occasionally turn into a ventricular tachycardia (VT) or a ventricular fibrillation (VF) beats which can immediately lead to the heart failure. Thus, it is important to periodically monitor the heart rhythms to manage and prevent the CVDs. Electrocardiogram (ECG) is a non-invasive medical tool that displays the rhythm and status of the heart. Therefore, automatic detection of irregular heart rhythms from ECG signals is a significant task in the field of cardiology. [[1]](https://arxiv.org/abs/1804.06812)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the approach used in:\n",
    "'ECG arrhythmia classification using a 2-D convolutional neural network' [[1]](https://arxiv.org/abs/1804.06812) (from here on, referred to as 'the paper')\n",
    "\n",
    "This approach converts a dataset of ECG signals from the **MIT-BIH Arrhythmia database** into a set of 128x128 grayscale ECG images. A 2D Convolutional Neural Network is then trained to classify the images between 1 of 8 classes of arrhythmias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the interest of time, the conversion from signal to over a 100K, 128x128 images has been done for you. A few example images are shown below:\n",
    "\n",
    "![](./images/Screenshot from 2018-08-23 08-55-40.png)\n",
    "\n",
    "As you can see, there are a total of 8 classes, consisting of 7 arrhythmias and a normal beat class (NOR). Each class is in a separate folder in the dataset.\n",
    "\n",
    "Download the dataset by running the following command from a terminal window on your computing device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wget www.deepbrainchain.com/ecg_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model we are using is a 2D CNN consisting of stacked layers including convolutional layers, pooling layers and Batch Normalization Layers, among others. The paper shows it outperforms AlexNet and VGG16 architectures.\n",
    "\n",
    "![](./images/model_arch.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model using the DBC network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be training the model using the DBC network of GPUs. \n",
    "\n",
    "\n",
    "1) Firstly, download the latest version of dbc using the instructions provided in the DBC [AI Manual](https://github.com/DeepBrainChain/deepbrainchain-release/releases/download/0.3.4.0/DBC.AI.Users.Manual_En.pdf)\n",
    "\n",
    "2) Login to the DBC website and purchase a machine for the desired duration. We recommend choosing 4-8 GPUs for 20 or 12 hours respectively\n",
    "\n",
    "3) Enter the machine id for your GPU machine in the task.conf file as per the AI Manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading the dataset and code directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following in your terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /path_to_dbc_directory/dbc_repo/tool \n",
    "bash ./dbc_upload /path_to_data_directory/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the resulting DIR_HASH and enter it in the 'dataset_dir' entry in the task.conf file.\n",
    "\n",
    "Next run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bash ./dbc_upload /path_to_code_directory/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the resulting DIR_HASH and enter it in the 'code_dir' entry in the task.conf file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting the task file for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your DBC terminal, submit your completed task file by executing the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start -c /path/to/file/task.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task file specifies an execution file run.sh that executes the training script train_keras.py when the DBC task is initiated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the status of the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the **node_id** for your task. It can be used to check the status via the latest standard output prints that are generated.\n",
    "\n",
    "Run the following in your dbc terminal to check the status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs -t node_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading and reviewing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the list -a command shows 'job completed', it means that your task has been completed. Well done!\n",
    "\n",
    "Now use the following command to download the results of your task for analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result -t node_id -o /custom_save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [10 pts] Q1 - Visualize results\n",
    "\n",
    "Visualizations offer a human readable views to understand the behavour of a model. They are often used in papers for comparisions between several iterations or different models\n",
    "\n",
    "The logs of the results are in /sdfsdf/\n",
    "\n",
    "Plot the loss vs epochs using the python library Matplotlib, or any other library you prefer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [10 pts] Q2 - CNN Layers\n",
    "\n",
    "Section 'The Model' in this tutorial names 3 types of layers used in the chosen architecure. Describe the function of each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [30 pts] Q3 - Data Augmentation\n",
    "\n",
    "Data augmentation is a tried and tested method to expand the size of a dataset, and improve performance of a trained network.\n",
    "\n",
    "The paper [1] suggests using 9 different cropping methods, randomly during the training session.\n",
    "\n",
    "Modify the function generator() in DataGenerator.py to augment the dataset randomly during training. \n",
    "\n",
    "You may use the medium post: www.medium.com as a hint on the 9 cropping functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [50 pts] Q3 - Different Models\n",
    "\n",
    "Modify the model model_keras.py and test an different model for training.\n",
    "\n",
    "\n",
    "Here are a few examples:\n",
    "- AlexNet\n",
    "- VGG16\n",
    "- ResNet50\n",
    "- InceptionV3\n",
    "\n",
    "An important skill in deep learning is to try different approaches and benchmark results.\n",
    "\n",
    "\n",
    "Train your custom model and answer the following questions:\n",
    "\n",
    "Did your results improve or not?\n",
    "What could be the reason for improvement or deterioration of the results?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
